id,business_key,validation_name,description,type
1,Column Exist,expect_column_to_exist,Expect the specified column to exist,spark
2,Multiple column check,expect_table_columns_to_match_ordered_list,Expect the columns to exactly match a specified list.,spark
3,Match column Set,expect_table_columns_to_match_set,Expect the columns to match a specified set.,spark
4,Column count,expect_table_column_count_to_be_between,Expect the number of columns to be between two values,spark
5,Exact Column Count,expect_table_column_count_to_equal,Expect the number of columns to equal a value.,spark
6,Row Countt,expect_table_row_count_to_be_between,Expect the number of rows to be between two values.,spark
7,Exact Row Count,expect_table_row_count_to_equal,Expect the number of rows to equal a value.,spark
8,Unique,expect_column_values_to_be_unique,Expect each column value to be unique.,spark
9,Not Null,expect_column_values_to_not_be_null,Expect column values to not be null.,spark
10,Multiple column Uniquness,expect_compound_columns_to_be_unique,"Expect that the columns are unique together, e.g. a multi-column primary key Note that all instances of any duplicates are considered failed",spark
11,Null,expect_column_values_to_be_null,Expect column values to be null.,spark
12,DataType Check,expect_column_values_to_be_of_type,Expect a column to contain values of a specified data type.,spark
13,Mulitiple Datatype Check,expect_column_values_to_be_in_type_list,Expect a column to contain values from a specified type list.,spark
14,Value to be in the set,expect_column_values_to_be_in_set,Expect each column value to be in a given set.,spark
15,Value not to be in the set,expect_column_values_to_not_be_in_set,Expect each column value not to be in a given set.,spark
16,Value Between,expect_column_values_to_be_between,Expect column entries to be between a minimum value and a maximum value (inclusive),spark
17,Value Increasing,expect_column_values_to_be_increasing,Expect column values to be increasing.,spark
18,Value Decreasing,expect_column_values_to_be_decreasing,Expect column values to be decreasing.,spark
19,Value to be the between,expect_column_value_lengths_to_be_between,Expect column entries to be strings with length between a minimum value and a maximum value (inclusive).,spark
20,Value Equal,expect_column_value_lengths_to_equal,Expect column entries to be strings with length equal to the provided value,spark
21,Value Regex,expect_column_values_to_match_regex,Expect column entries to be strings that match a given regular expression.,spark
22,Value not match the regex,expect_column_values_to_not_match_regex,Expect column entries to be strings that do NOT match a given regular expression,spark
23,Value match regex list,expect_column_values_to_match_regex_list,Expect the column entries to be strings that can be matched to either any of or all of a list of regular expressions. Matches can be anywhere in the string.,spark
24,Value not match regex list,expect_column_values_to_not_match_regex_list,Expect the column entries to be strings that do not match any of a list of regular expressions. Matches can be anywhere in the string.,spark
25,strftime format,expect_column_values_to_match_strftime_format,Expect column entries to be strings representing a date or time with a given format,spark
26,dateutil parseable,expect_column_values_to_be_dateutil_parseable,Expect column entries to be parsable using dateutil,pandas
27,Value be json parseable,expect_column_values_to_be_json_parseable,Expect column entries to be data written in JavaScript Object Notation.,pandas
28,Value match json schema,expect_column_values_to_match_json_schema,Expect column entries to be JSON objects matching a given JSON schema.,spark
29,Distinct,expect_column_distinct_values_to_be_in_set,Expect the set of distinct column values to be contained by a given set.,spark
30,,expect_column_distinct_values_to_equal_set,Expect the set of distinct column values to equal a given set,spark
31,Distinct,expect_column_distinct_values_to_contain_set,Expect the set of distinct column values to contain a given set,spark
32,Mean,expect_column_mean_to_be_between,Expect the column mean to be between a minimum value and a maximum value (inclusive).,spark
33,Median,expect_column_median_to_be_between,Expect the column median to be between a minimum value and a maximum value.,spark
34,Quantile,expect_column_quantile_values_to_be_between,Expect specific provided column quantiles to be between provided minimum and maximum values.,spark
35,Standard Deviation,expect_column_stdev_to_be_between,Expect the column standard deviation to be between a minimum value and a maximum value. Uses sample standard deviation (normalized by N-1).,spark
36,Unique Value Count,expect_column_unique_value_count_to_be_between,Expect the number of unique values to be between a minimum value and a maximum value,spark
37,Proportion Of Unique Values,expect_column_proportion_of_unique_values_to_be_between,Expect the proportion of unique values to be between a minimum value and a maximum value.,spark
38,Most Common Value ,expect_column_most_common_value_to_be_in_set,Expect the most common value to be within the designated value set,spark
39,Sum,expect_column_sum_to_be_between,Expect the column to sum to be between an min and max value,spark
40,Min ,expect_column_min_to_be_between,Expect the column minimum to be between an min and max value,spark
41,Max,expect_column_max_to_be_between,Expect the column max to be between an min and max value,spark
42,Kl Divergence ,expect_column_kl_divergence_to_be_less_than,Expect the Kulback-Leibler (KL) divergence (relative entropy) of the specified column with respect to the partition object to be lower than the provided threshold.,spark
43,Pair Values,expect_column_pair_values_to_be_equal,Expect the values in column A to be the same as column B.,spark
44,A Greater than B,expect_column_pair_values_A_to_be_greater_than_B,Expect values in column A to be greater than column B,spark
45,Pair Values in Set,expect_column_pair_values_to_be_in_set,Expect paired values from columns A and B to belong to a set of valid pairs.,spark
46,Multicolumn Sum,expect_multicolumn_sum_to_equal,Expects that sum of all rows for a set of columns is equal to a specific value,spark
47,Z-Score,expect_column_value_z_scores_to_be_less_than,Expects that Z-Score of the column less than the given one.,spark
48,Value At index,expect_value_at_index,Check for a specified value at a given index location within each element of the column,pandas
49,,expect_table_row_count_to_equal_other_table,Expect the number of rows to equal the number in another table.,spark
50,,expect_select_column_values_to_be_unique_within_record,Expect that the column value to be unique in the particular record,spark
51,,expect_foreign_keys_in_column_a_to_exist_in_column_b,Ensure that values in the column of ColumnA are in a valueset provided in the Column B,spark
52,,expect_column_wasserstein_distance_to_be_less_than,Expect the column to wasserstein distance to be less than given value,pandas
53,Value not like Pattern List,expect_column_values_to_not_match_like_pattern_list,Expect column entries to be strings that do NOT match any of a provided list of like patterns expressions.,spark
54,Value  Not Like Pattern,expect_column_values_to_not_match_like_pattern,Expect column entries to be strings that do NOT match a given like pattern expression.,spark
55,Special Character,expect_column_values_to_not_contain_special_characters,Expect column entries to not contain special characters,pandas
56,Not A Char,expect_column_values_to_not_contain_character,Expect the set of column values to not contain a given character.,pandas
57,XML Match,expect_column_values_to_match_xml_schema,Expect column entries to be XML documents matching a given,spark
58,Like Pattern List ,expect_column_values_to_match_like_pattern_list,Expect column entries to be strings that match any of a provided list of like patterns expressions.,spark
59,Like Pattern,expect_column_values_to_match_like_pattern,Expect column entries to be strings that match a given like pattern expression.,spark
60,,expect_column_values_to_follow_rule,This expectation compares all rows of a column against a given input expression.,pandas
61,Email,expect_column_values_to_contain_valid_email,Expect values in column should be a mail,spark
62,,expect_column_values_to_change_between,"Given a list of numeric values,check if the difference between the current and the previous row is within the expected difference range.",pandas
63,,expect_column_values_to_be_xml_parseable,Expect column entries to be data written in XML.,spark
64,,expect_column_values_to_be_valid_wikipedia_articles,This Expectation checks whether a column contains valid titles/slugs of Wikipedia articles.,pandas
65,URL,expect_column_values_to_be_valid_urls,Expect column to be a valid URL,pandas
66,String Integer Increasing,expect_column_values_to_be_string_integers_increasing,Expect a column to contain string-typed integers to be increasing.,spark
67,Secure Password,expect_column_values_to_be_secure_passwords,"Expect column entries to be secure passwords, as defined by expectation parameters.",pandas
68,Ascii,expect_column_values_to_be_ascii,Expect the set of column values to be ASCII characters,spark
69,Alphabetical,expect_column_values_to_be_alphabetical,Expect the set of column values to be Alphabetic,pandas
70,Not Outliers,expect_column_values_to_not_be_outliers,Expect that value is not a outliers.Outlier is defined as being any point of data that lies over 1.5 IQRs below the first quartile (Q1) or above the third quartile (Q3)in a data set.,spark
71,Zipcode,expect_column_values_to_be_us_zipcode_within_mile_radius_of_given_zipcode,"Given a zipcode and a radius, this expectation checks that all zipcodes in a column of a table are within a specified radius, in miles, of the given zipcode.",pandas
72,Normal Distributed,expect_column_values_to_be_normally_distributed,Test whether column values are normally distributed. NaN values are omitted.,pandas
73,,expect_column_values_to_be_edtf_parseable,Expect column entries to be parsable using the [Extended Date/Time Format (EDTF) specification],pandas
74,Non Bot,expect_column_values_to_be_a_non_bot_user_agent,Expect useragents to be non bots,pandas
75,Geo Region,expect_column_values_point_within_geo_region,"This expectation will check a (longitude, latitude) tuple to see if it falls within a country input by the",pandas
76,,expect_column_values_number_of_decimal_places_to_equal,"This expectation tests if all the values in a column has the same number of decimal places as the inputted number of decimal places. In the case where the decimal places are all 0s (an integer),the value automatically passes.",pandas
77,,expect_column_values_are_in_language,Expect the column to be in a specified language.,pandas
78,SKEW,expect_column_skew_to_be_between,Expect column skew to be between. Currently tests against Gamma and Beta distributions,pandas
79,Kurtosis,expect_column_kurtosis_to_be_between,"Expect column Kurtosis to be between. Test values are drawn from various distributions (uniform, normal, gamma, student-t)",pandas
80,,expect_column_distribution_to_match_benfords_law,Tests whether data matches Benford's Law Fraud Detection Algorithm.,pandas
81,,expect_column_discrete_entropy_to_be_between,Expect the column discrete entropy to be between a minimum value and a maximum value.,spark
82,,expect_table_row_count_to_be_equal_to_other_tables,,spark
